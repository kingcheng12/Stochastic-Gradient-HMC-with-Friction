{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemention of Stochastic Gradient Hamiltonian Monte Carlo with Friction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The purpose of this report is to implement the SGHMC (stochastic gradient Hamiltonian Monte Carlo) created by Tianqi Chen, Emily B. Fox and Carlos Guestrin. SGHMC algorithm takes advantage from minibatch and speed up the code. In this report, we will first illustrate the details of the algorithm, implement and optimize it in code, and then apply it for simulated data and real data. Comparisons between different version of HMC will be made in terms of accuracy and running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "HMC is a widely used MCMC sampling algorithm. It resembles energy system by imitating potential energy by the target distribution as well as kinetic energy by 'momentum' auxiliary variables.\n",
    "\n",
    "Whereas HMC will explore the state space quickly, there is one limitation of HMC: Gradient of the potential energy function is essential for HMC algorithm and it ultilize the whole data set, which in modern days are in millions or even billions. The hugh computational cost encourages ideas of using minibatches instead of the whole data set. It is evident that a naive algorithm that simply replaces the whole data set by minibatches is not consistent. Accordingly, we need to add a MH (Metropolis-Hasting) correction for keeping consistency. However, the MH correction also needs considerable amount of computation power.\n",
    "\n",
    "In the paper by Tianqi Chen, Emily B. Fox and Carlos Guestrin, a new algorithm proposal is made by adding a friction term to the 'momentum' variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Algorithm\n",
    "\n",
    "PROCEDURE FOR COMPUTING THE NEEDED PARAMETERS\n",
    "\n",
    "Suppose we have data $x_i \\sim p(x|\\theta), ~i=1,...,n$. We want to estimate $\\theta$ by sampling from the posterior distribution $p(\\theta|x)$.\n",
    "\n",
    "The HMC procedure is as below:\n",
    "\n",
    "Set initial value $\\theta^{(0)}$, n = number of epochs\n",
    "\n",
    "For t = 1,..., n\n",
    "1. Sample $r^{(t)} \\sim N(0,M)$, where r is the momentum variable and M is the mass matrix\n",
    "2. Set $(\\theta_0, r_0)$ = $(\\theta^{(t)}, r^{(t)})$\n",
    "3. for i = 1,...,m, where m is the number of minibatchs\n",
    "    - $\\theta_i=\\theta_{i-1} + \\epsilon_t M^{-1} r_{i-1}$ \n",
    "    - $r_i = r_{i-1} - \\epsilon_t \\nabla \\tilde{U}(\\theta_i) - \\epsilon_t C M^{-1} r_{i-1} + N(0,2(C-\\hat{B})\\epsilon_t)$, where C is a user specified friction term and $\\hat{B} = \\frac{1}{2}\\epsilon_t V_t$, $V_t$ is the estimated fisher information\n",
    "4. $(\\theta^{(t+1)}, r^{(t+1)})$ = $(\\theta_m, r_m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Modules\n",
    "\n",
    "The functions we create and archive in package 'sghmc' are SGHMC and SGHMC_parallel, with inputs:\n",
    "\n",
    "- theta0: The initial values chosen by user\n",
    "- X: Data\n",
    "- gradU: The function compute gradient of $U(\\theta)$ based on data and current theta\n",
    "- eps: Learning rate\n",
    "- sample_size: Number of samples generated from posterior distribution\n",
    "- B: Noise model chosen by user\n",
    "- C: Upper bound of B s.t. (C-B) is positive definite\n",
    "- batch_size: Number of data in each batch\n",
    "- burnin: Number of samples dropped initially for the HMC samples\n",
    "- n: Number of cores used, only applicable for SGHMC_parallel\n",
    "- M: The mass matrix, set to be identity in default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use the most basic code to implement the algorithm.\n",
    "\n",
    "We profile the code to see which part takes most of the time to run. It turns out that the multivariate normal sampling costs most of the time.\n",
    "\n",
    "Then we use statistical knowledge to improve the efficiency of sampling from multivariate normal distribution, and then profile the code again. The function computing gradient of U takes significant amount of time. We decide to use numba to reduce its time consuming feature.\n",
    "\n",
    "We used paralell process and further reduce the running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the function from each optimizing step to $U(\\theta)$ below (first example in 'Application to Simulated Data' section) in order to illustrate the increasing efficiency. The parameters used for testing are: \n",
    "\n",
    "|Algorithm|basic function|vectorized function|function with numba|function with parallel|\n",
    "|---------|--------------|-------------------|-------------------|----------------------|\n",
    "|Time     |\n",
    "\n",
    "It turns out that each step we saved certain amount of time...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example From Paper\n",
    "\n",
    "This is the example from paper. The basic setting is as following:\n",
    "\n",
    "- $U(\\theta) = -2\\theta^2+\\theta^4$\n",
    "- $\\nabla \\tilde{U}(\\theta) = \\nabla U(\\theta) + N(0,4)$\n",
    "\n",
    "To compare between the simulated distribution and the true distribution, below are the simulated density (upper) and true density (below):\n",
    "<img src=\"U_in_paper.png\">\n",
    "<img src=\"real_U_in_paper.png\">\n",
    "\n",
    "It is evident that two densities have very similar shape. This illsturate that our sghmc module works well in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of Mixture Normal\n",
    "\n",
    "We simulate 200 samples from distribution with density $p(x)=0.5N(x|\\mu_1,1)+0.5N(x|\\mu_1,1)$, where $\\mu=(\\mu_1, \\mu_2) = (5,-5)$. \n",
    "\n",
    "Suppose we do not know true $\\mu$ and want to estimate them. We will use our sghmc method to approximate $\\mu$.\n",
    "\n",
    "The first plot is by SGHMC.\n",
    "\n",
    "<img src=\"mixture_norm.png\">\n",
    "\n",
    "The second plot is by SGHMC_parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of Linear Model\n",
    "\n",
    "We want to use sghmc to estimate the parameters of linear model. We perform the algorithm on simulated data with known true parameters, and compare the resulting estimates to the true paramaters.\n",
    "\n",
    "Suppose we want to simulate 100 observations from a linear model with a 1-dim response variable and 3 predictors, the model could be expressed as below:\n",
    "\n",
    "$y|x,\\alpha, \\beta, \\sigma^2 \\sim N(\\alpha + x^T\\beta, \\sigma^2)$\n",
    "\n",
    "where y is the response variables, x are the vector of 3 predictors with shape (3,1), $\\alpha$ are the intercept, $\\beta$ are the vector with shape (3,1) of coefficeints for 3 predictor, $\\sigma^2$ is the variance of noise.\n",
    "\n",
    "To sample y from above model, we first sample x from $MVN(0,I_3)$. We set true $\\alpha=1$, true $\\beta=(2,3,4)^T$ and true $\\sigma^2=1$. Next, we sample noise from $N(0,\\sigma^2)$. Finally we compute $y = \\alpha + x^T\\beta + noise$. \n",
    "\n",
    "Repeat the above procedure 100 times to generate 100 samples of $x,y$. Note that we may vectorize y and matrixrize x so that we may compute y collectively.\n",
    "\n",
    "Now apply our sghmc module for sampling from $p(\\alpha,\\beta,\\sigma^2|Y,X)$. Note that we need to log transform $\\sigma^2$ since we need the hmc algorithm to explore the whole state space freely. The true $log(\\sigma^2) = log(1)=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRPTION OF FUNCTION INPUTS\n",
    "\n",
    "The results are below:\n",
    "\n",
    "|parameter     |$\\alpha$|$\\beta_1$|$\\beta_2$|$\\beta_3$| $log(\\sigma^2)$ |\n",
    "|--------------|--------|---------|---------|---------|-----------------|\n",
    "|Posterior mean|0.985   |1.875    |2.855    |3.922    |-0.097           |\n",
    "\n",
    "The posterior are close to the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rmse based on the posterior estimation of parameters is 9.09.\n",
    "\n",
    "The plot between true y and estimated y are blow:\n",
    "\n",
    "<img src=\"sim_lm_error.png\">\n",
    "\n",
    "It is clear that the in general, true y and estimated y are close since they are along the 45 degree line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 1: linear model on azdiabetes data set\n",
    "\n",
    "The data set is available on http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/.\n",
    "\n",
    "The data set is about diabete. This data set contains 532 observations and 7 variables. For simplicity and purpose of illustration, we will only use the first 5 variables:\n",
    "\n",
    "- npreg: Number of pregancy\n",
    "- glu: glucose level\n",
    "- bp: Blood pressure\n",
    "- skin: Skin thickness\n",
    "- bmi: Body mass index\n",
    "\n",
    "In this example, we will try to regress glu on other variables (npreg, bp skin, bmi, ped age) with our modules.\n",
    "\n",
    "We estimate the coefficient as following:\n",
    "\n",
    "|Coefficient|$\\alpha$|$\\beta_1$|$\\beta_2$|$\\beta_3$|$\\beta_4$|$log(\\sigma^2)$|\n",
    "|-----------|--------|---------|---------|---------|---------|---------------|\n",
    "|value      |2.985   |0.967    |0.848    |0.153    |1.469    |6.899          |\n",
    "\n",
    "With the estimated coefficients, we estimate y and plot true y against estimated y\n",
    "\n",
    "<img src=\"glu_estimation.png\">\n",
    "\n",
    "We could see that estimation is not so accurate, and this is because of the non-linearity of the data. \n",
    "\n",
    "We choose another real data that possesses linearity below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 2: linear model on salary data\n",
    "\n",
    "This data set is available on https://www.kaggle.com/vihansp/salary-data.\n",
    "\n",
    "The data set is about salary rate. It contains 30 observations and two variables, the yearly salary and and years of experience.\n",
    "\n",
    "We will fit a simple regression model by regressing yearly salary on years of experience. We first tranform yearly salary by shrinking it 10000 times in order to regularize. Then we apply our module to estimate the coefficients\n",
    "\n",
    "We estimate the coefficient as following:\n",
    "\n",
    "|Coefficient|$\\alpha$|$\\beta_1$|$log(\\sigma^2)$|\n",
    "|-----------|--------|---------|---------------|\n",
    "|value      |1.878   |1.040    |-0.569          |\n",
    "\n",
    "The following is the plot of true salary against estimated salary:\n",
    "\n",
    "<img src=\"salary_estimation.png\">\n",
    "\n",
    "Based on the plot, we clearly see that the points are near the 45 degree line, which means that our module is doing well in estimating the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competing Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare our algorithm with Pyhmc and Pystan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
